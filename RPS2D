class RPS2D(object):
    def __init__(self, 
                 sf: Union[float, Tuple[float, float]] = 1.0,
                 p: float = 1.0):
        self.swap_factor = sf
        self.augmentation_prob = p
        self.s = 1  
        
    def __call__(self, x: Union[Image.Image, torch.Tensor]) -> Union[Image.Image, torch.Tensor]:
        if random.random() > self.augmentation_prob:
            return x

        is_tensor = isinstance(x, torch.Tensor)
        if is_tensor:
            device = x.device
            dtype = x.dtype
            x_np = x.permute(1, 2, 0).cpu().numpy() 
            mode = 'RGB' if x_np.shape[-1] == 3 else 'L'
            x_pil = Image.fromarray((x_np * 255).astype(np.uint8), mode)
        else:
            x_pil = x

        if isinstance(self.swap_factor, tuple):
            swap_ratio = random.uniform(*self.swap_factor)
        else:
            swap_ratio = float(self.swap_factor)

        img_arr = np.array(x_pil)
        h, w = img_arr.shape[:2]
        h_half, w_half = h//2, w//2
        u = h//2  
        
        def get_points(length):
            points = list(range(self.s, length-self.s, self.s))
            points = random.sample(points, 2)
            points.sort()
            return [int(p*swap_ratio) for p in points]
        
        h_points = get_points(h)
        w_points = [p//2 for p in h_points]
        w1, w2 = w_points[0] + w_half, w_points[1] + w_half
        
        w_vert_points = get_points(w)
        hw_points = [p//2 for p in w_vert_points]
        hw1, hw2 = hw_points[0] + h_half, hw_points[1] + h_half
        
        d_points = get_points(u)
        d1, d2 = [p + u for p in d_points]

        def process_pair(img, coords):
            roi1 = img.crop(coords[0])
            roi2 = img.crop(coords[1])
            deleted = img.copy()
            deleted.paste((0, 0, 0) if img.mode == 'RGB' else 0, coords[0])
            deleted.paste((0, 0, 0) if img.mode == 'RGB' else 0, coords[1])
            return deleted, roi1, roi2

        transformations = {
            'h': [(w_points[0], h_points[0], w_points[1], h_points[1]), 
                 (w1, h_points[0], w2, h_points[1])],
            'w': [(w_vert_points[0], hw_points[0], w_vert_points[1], hw_points[1]),
                 (w_vert_points[0], hw1, w_vert_points[1], hw2)],
            'u': [(d_points[0], d_points[0], d_points[1], d_points[1]),
                 (d1, d_points[0] + u, d2, d_points[1] + u)],
            'd': [(d_points[0], d_points[0] + u, d_points[1], d_points[1] + u),
                 (d1, d_points[0], d2, d_points[1])]
        }

        results = {}
        for key, coords in transformations.items():
            deleted, p1, p2 = process_pair(x_pil, coords)
            results[key] = (deleted, p1, p2, coords)

        # Create transformed images
        new_samples = [
            self._paste_patches(results['h'][0], [(w1, h_points[0], results['h'][1]), 
                                              (w_points[0], h_points[0], results['h'][2])]),
            self._paste_patches(results['w'][0], [(w_vert_points[0], hw1, results['w'][1]),
                                              (w_vert_points[0], hw_points[0], results['w'][2])]),
            self._paste_patches(results['u'][0], [(d1, d_points[0] + u, results['u'][1]),
                                              (d_points[0], d_points[0], results['u'][2])]),
            self._paste_patches(results['d'][0], [(d1, d_points[0], results['d'][1]),
                                              (d_points[0], d_points[0] + u, results['d'][2])])
        ]
        
        random.shuffle(new_samples)
        output = random.choice(new_samples)

        if is_tensor:
            output_np = np.array(output).astype(np.float32) / 255.0
            output = torch.from_numpy(output_np).permute(2, 0, 1).to(device=device, dtype=dtype)
        
        return output
    
    def _paste_patches(self, base_img, patches):
        img = base_img.copy()
        for x, y, patch in patches:
            img.paste(patch, (x, y))
        return img
